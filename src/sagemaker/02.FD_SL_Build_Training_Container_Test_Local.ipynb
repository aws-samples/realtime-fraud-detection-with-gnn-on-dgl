{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to run docker building and running\n",
    "\n",
    "This notebook shows the 1st time training process of a fraud detection model using graph neural networks in the Solution.\n",
    "\n",
    "This notebook assumes the transaction data has been dumped out from the graph database, such as Neptune DB, and copied to S3 bukets. So the input data has already in S3.\n",
    "\n",
    "Then we create a launch of training job using the SageMaker framework estimator to train a graph neural network model with DGL.\n",
    "\n",
    "\n",
    "## Step 1: build our own docker image\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- An AWS account\n",
    "- Configure credential of aws cli(the credential has sagemaker, ecr permissions)\n",
    "- Install Docker Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com\n",
    "\n",
    "# run below line if you are using AWS China regions\n",
    "#! aws ecr get-login-password --region cn-north-1 | docker login --username AWS --password-stdin 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'fraud-detection-with-gnn-on-dgl/training'\n",
    "! docker build -t $image_name ./FD_SL_DGL/gnn_fraud_detection_dgl\n",
    "\n",
    "# run below line if you are using AWS China regions\n",
    "# ! docker build --build-arg=IMAGE_REPO=727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn -t fraud-detection-with-gnn-on-dgl/training ./FD_SL_DGL/gnn_fraud_detection_dgl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test this docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "- Complete the steps in notebook [01.FD_SL_Process_IEEE-CIS_Dataset](./01.FD_SL_Process_IEEE-CIS_Dataset.ipynb)\n",
    "- install **[docker-compose](https://docs.docker.com/compose/install/)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Restore the variables from previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "def resolve_sm_role():\n",
    "    region = boto3.session.Session().region_name\n",
    "    client = boto3.client('iam', region_name=region)\n",
    "    response_roles = client.list_roles(\n",
    "        PathPrefix='/',\n",
    "        # Marker='string',\n",
    "        MaxItems=999\n",
    "    )\n",
    "    for role in response_roles['Roles']:\n",
    "        if role['RoleName'].startswith('AmazonSageMaker-ExecutionRole-'):\n",
    "            print('Resolved SageMaker IAM Role to: ' + str(role))\n",
    "            return role['Arn']\n",
    "    raise Exception('Could not resolve what should be the SageMaker role to be used')\n",
    "    \n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = resolve_sm_role()\n",
    "    \n",
    "print(role)\n",
    "sagemaker_exec_role = role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If you meet error when running above step, please refer to [this doc to create SageMaker execution role](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Pre-processed data from S3\n",
    "\n",
    "The dataset used in this Solution is the [IEEE-CIS Fraud Detection dataset](https://www.kaggle.com/c/ieee-fraud-detection/data?select=train_transaction.csv) which is a typical example of financial transactions dataset that many companies have. The dataset consists of two tables:\n",
    "\n",
    "* **Transactions**: Records transactions and metadata about transactions between two users. Examples of columns include the product code for the transaction and features on the card used for the transaction. \n",
    "* **Identity**: Contains information about the identity users performing transactions. Examples of columns here include the device type and device ids used.\n",
    "\n",
    "This notebook assumes that the two data tables had been pre-processed, mimicing the 1st time data preparation. \n",
    "\n",
    "**Current version uses the pre-processed data in nearly raw format, include all relation files, a feature file, a tag file, and a test index files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_folder = 'model_output'\n",
    "\n",
    "output_path = f's3://{default_bucket}/{model_output_folder}'\n",
    "\n",
    "print(processed_data)\n",
    "print(output_path)\n",
    "\n",
    "from os import path\n",
    "from sagemaker.s3 import S3Downloader\n",
    "import sagemaker\n",
    "\n",
    "sagemakerSession = sagemaker.session.Session(boto3.session.Session(region_name=current_region))\n",
    "processed_files = S3Downloader.list(processed_data, sagemaker_session=sagemakerSession)\n",
    "print(\"===== Processed Files =====\")\n",
    "print('\\n'.join(processed_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Graph Neural Network with DGL\n",
    "\n",
    "Graph Neural Networks work by learning representation for nodes or edges of a graph that are well suited for some downstream task. We can model the fraud detection problem as a node classification task, and the goal of the graph neural network would be to learn how to use information from the topology of the sub-graph for each transaction node to transform the node's features to a representation space where the node can be easily classified as fraud or not.\n",
    "\n",
    "Specifically, we will be using a relational graph convolutional neural network model (R-GCN) on a heterogeneous graph since we have nodes and edges of different types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "To train the graph neural network, we need to define a few hyperparameters that determine properties such as the class of graph neural network models we will be using, the network architecture and the optimizer and optimization parameters. \n",
    "\n",
    "Here we're setting only a few of the hyperparameters, to see all the hyperparameters and their default values, see `FD_SL_DGL/gnn_fraud_detection_dgl/estimator_fns.py`. The parameters set below are:\n",
    "\n",
    "* **`nodes`** is the name of the file that contains the `node_id`s of the target nodes and the node features.\n",
    "* **`edges`** is a regular expression that when expanded lists all the filenames for the edgelists\n",
    "* **`labels`** is the name of the file tha contains the target `node_id`s and their labels\n",
    "\n",
    "The following hyperparameters can be tuned and adjusted to improve model performance\n",
    "* **embedding-size** is the size of the embedding dimension for non target nodes\n",
    "* **n-layers** is the number of GNN layers in the model\n",
    "* **n-epochs** is the number of training epochs for the model training job\n",
    "* **optimizer** is the optimization algorithm used for gradient based parameter updates\n",
    "* **lr** is the learning rate for parameter updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = \",\".join(map(lambda x: x.split(\"/\")[-1], [file for file in processed_files if \"relation\" in file]))\n",
    "params = {'nodes' : 'features.csv',\n",
    "          'edges': 'relation*',\n",
    "          'labels': 'tags.csv',\n",
    "          'embedding-size': 64,\n",
    "          'n-layers': 2,\n",
    "          'n-epochs': 100,\n",
    "          'optimizer': 'adam',\n",
    "          'lr': 4e-3\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Fit SageMaker Pytorch Estimator\n",
    "\n",
    "With the hyperparameters defined, then kick off the training job. Here use the Deep Graph Library (DGL), with Pytorch as the backend deep learning framework, to define and train the graph neural network. Amazon SageMaker makes it do this with the Framework estimators which have the deep learning frameworks already setup. Here, we create a SageMaker Pytorch estimator and pass in our model training script, hyperparameters, as well as the number and type of training instances specified.\n",
    "\n",
    "Then `fit` the estimator on the the training data location in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from time import strftime, gmtime\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "localSageMakerSession = LocalSession(boto_session=boto3.session.Session(region_name=current_region))\n",
    "estimator = Estimator(image_uri=image_name,\n",
    "                      role=sagemaker_exec_role,\n",
    "                      instance_count=1,\n",
    "                      instance_type='local',\n",
    "                      hyperparameters=params,\n",
    "                      output_path=output_path,\n",
    "                      sagemaker_session=localSageMakerSession)\n",
    "\n",
    "training_job_name = \"{}-{}\".format('GNN-FD-SL-DGL-Train', strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))\n",
    "print(training_job_name)\n",
    "\n",
    "estimator.fit({'train': processed_data}, job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is completed, the training instances are automatically saved and SageMaker stores the trained model and evaluation results to a location in S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repackage the model with custom code\n",
    "\n",
    "We will use custom code as program entry of model, we will download the model then repackge it as the structure with our custom entry program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'{output_path}/{training_job_name}/model.tar.gz'\n",
    "repackged_model_path = f'{output_path}/{training_job_name}/repackage-model.tar.gz'\n",
    "\n",
    "import tempfile\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "code_path = f'{output_path}/{training_job_name}/code/'\n",
    "\n",
    "! export AWS_DEFAULT_REGION=$current_region && aws s3 sync ./FD_SL_DGL/code $code_path\n",
    "! export AWS_DEFAULT_REGION=$current_region && ../lambda.d/repackage-model/repackage.sh $model_path $repackged_model_path $code_path $temp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store repackged_model_path\n",
    "%store sagemaker_exec_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}