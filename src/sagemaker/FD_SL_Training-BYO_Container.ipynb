{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection Solution Training Notebook with My Own Docker\n",
    "\n",
    "This notebook shows the 1st time training process of a fraud detection model using graph neural networks in the Solution.\n",
    "\n",
    "This notebook assumes the transaction data has been dumped out from the Neptune DB, and copied to S3 bukets. So the input data has already in S3.\n",
    "\n",
    "Then we create a launch of training job using the SageMaker framework estimator to train a graph neural network model with DGL.\n",
    "\n",
    "### Major difference from the Solution Training Notebook is using my own docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip uninstall sagemaker -y\n",
    "! pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker_graph_fraud_detection import config, container_build\n",
    "\n",
    "role = config.role\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Pre-processed data from S3\n",
    "\n",
    "The dataset used in this Solution is the [IEEE-CIS Fraud Detection dataset](https://www.kaggle.com/c/ieee-fraud-detection/data?select=train_transaction.csv) which is a typical example of financial transactions dataset that many companies have. The dataset consists of two tables:\n",
    "\n",
    "* **Transactions**: Records transactions and metadata about transactions between two users. Examples of columns include the product code for the transaction and features on the card used for the transaction. \n",
    "* **Identity**: Contains information about the identity users performing transactions. Examples of columns here include the device type and device ids used.\n",
    "\n",
    "This notebook assumes that the two data tables had been pre-processed, mimicing the 1st time data preparation. \n",
    "\n",
    "**Current version uses the pre-processed data in nearly raw format, include all relation files, a feature file, a tag file, and a test index files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with an S3 location or local path to point to customers' own dataset\n",
    "data_location = 'fraud-detection-solution'\n",
    "raw_data_folder = 'raw_data'\n",
    "processed_data_folder = 'processed_data'\n",
    "model_output_folder = 'model_output'\n",
    "\n",
    "processed_data = 's3://{}/{}'.format(data_location, processed_data_folder)\n",
    "output_path = 's3://{}/{}'.format(data_location, model_output_folder)\n",
    "\n",
    "print(processed_data)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the pre-processed data\n",
    "\n",
    "Here come the pre-processed file lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to modified this to Neptune dump files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from sagemaker.s3 import S3Downloader\n",
    "processed_files = S3Downloader.list(processed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Graph Neural Network with DGL\n",
    "\n",
    "Graph Neural Networks work by learning representation for nodes or edges of a graph that are well suited for some downstream task. We can model the fraud detection problem as a node classification task, and the goal of the graph neural network would be to learn how to use information from the topology of the sub-graph for each transaction node to transform the node's features to a representation space where the node can be easily classified as fraud or not.\n",
    "\n",
    "Specifically, we will be using a relational graph convolutional neural network model (R-GCN) on a heterogeneous graph since we have nodes and edges of different types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "To train the graph neural network, we need to define a few hyperparameters that determine properties such as the class of graph neural network models we will be using, the network architecture and the optimizer and optimization parameters. \n",
    "\n",
    "Here we're setting only a few of the hyperparameters, to see all the hyperparameters and their default values, see `dgl-fraud-detection/estimator_fns.py`. The parameters set below are:\n",
    "\n",
    "* **`nodes`** is the name of the file that contains the `node_id`s of the target nodes and the node features.\n",
    "* **`edges`** is a regular expression that when expanded lists all the filenames for the edgelists\n",
    "* **`labels`** is the name of the file tha contains the target `node_id`s and their labels\n",
    "\n",
    "The following hyperparameters can be tuned and adjusted to improve model performance\n",
    "* **embedding-size** is the size of the embedding dimension for non target nodes\n",
    "* **n-layers** is the number of GNN layers in the model\n",
    "* **n-epochs** is the number of training epochs for the model training job\n",
    "* **optimizer** is the optimization algorithm used for gradient based parameter updates\n",
    "* **lr** is the learning rate for parameter updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = \",\".join(map(lambda x: x.split(\"/\")[-1], [file for file in processed_files if \"relation\" in file]))\n",
    "params = {'nodes' : 'features.csv',\n",
    "          'edges': 'relation*',\n",
    "          'labels': 'tags.csv',\n",
    "          'embedding-size': 64,\n",
    "          'n-layers': 2,\n",
    "          'n-epochs': 10,\n",
    "          'optimizer': 'adam',\n",
    "          'lr': 1e-2\n",
    "        }\n",
    "\n",
    "# print(\"Graph will be constructed using the following edgelists:\\n{}\" .format('\\n'.join(edges.split(\",\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Fit SageMaker Pytorch Estimator\n",
    "\n",
    "With the hyperparameters defined, then kick off the training job. Here use the Deep Graph Library (DGL), with Pytorch as the backend deep learning framework, to define and train the graph neural network. Amazon SageMaker makes it do this with the Framework estimators which have the deep learning frameworks already setup. Here, we create a SageMaker Pytorch estimator and pass in our model training script, hyperparameters, as well as the number and type of training instances specified.\n",
    "\n",
    "Then `fit` the estimator on the the training data location in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime, gmtime\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "estimator = Estimator(image_uri='510768346845.dkr.ecr.cn-north-1.amazonaws.com.cn/pytorch-extending-our-containers-gnn-fraud-detection-solution:latest',\n",
    "                      role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.c5.4xlarge',\n",
    "                      hyperparameters=params,\n",
    "                      output_path=output_path,\n",
    "                      disable_profiler=True,\n",
    "                      sagemaker_session=sess)\n",
    "\n",
    "training_job_name = \"{}-{}\".format('GNN_FD_SL_DGL_Train', strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))\n",
    "print(training_job_name)\n",
    "\n",
    "estimator.fit({'train': processed_data}, job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is completed, the training instances are automatically saved and SageMaker stores the trained model and evaluation results to a location in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
